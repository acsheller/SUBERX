{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f90f37-d975-49cc-9ff8-e118b25232ae",
   "metadata": {},
   "source": [
    "# System Preparation \n",
    "\n",
    "This notebook serves as notes for reference to getting setup to develop with SUBER.\n",
    "\n",
    "- [GPU Preparation](#gpu_prep)\n",
    "- [PyTorch Installation](#torch_install)\n",
    "- [Pytorch Examples]()\n",
    "- [Transformers and Tokenizers]()\n",
    "\n",
    "TODO -- fix links above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9042aca-73bd-4764-a169-56a8188bd4b9",
   "metadata": {},
   "source": [
    "## <a href=\"gpu_prep\">GPU Preparation</a>\n",
    "\n",
    "GPU and nvcc (aka cuda) versions should be within the same major version. I've noticed that Ubuntu 22.04 loads on some systems have been way out of **alignment**. Try to get them at the same version.\n",
    "\n",
    "\n",
    "```\n",
    "sudo apt-get purge 'nvidia*' 'cuda*'\n",
    "\n",
    "sudo apt-get install nvidia-driver-535\n",
    "\n",
    "sudo reboot\n",
    "\n",
    "wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda_12.2.0_535.54.03_linux.run\n",
    "\n",
    "chmod a+x cuda_12.2.0_535.54.03_linux.run\n",
    " \n",
    "sudo ./cuda_12.2.0_535.54.03_linux.run # And follow the prompts\n",
    "\n",
    "# Edit your .bashrc and put these in. But don't put the hastags in front of them.\n",
    "# export PATH=/usr/local/cuda-12.2/bin${PATH:+:${PATH}}\n",
    "#export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n",
    "\n",
    "\n",
    "# I also had to do this.  If you cannot type nvcc --version then you need to check the permissions.\n",
    "sudo chmod -R 755 /usr/local/cuda-12.2\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "The results should be something like this:\n",
    "\n",
    "```\n",
    "acshell@ip-10-114-92-249:~$ nvidia-smi | grep -i \"cuda version\" | awk '{print $9}'\n",
    "12.2\n",
    "acshell@ip-10-114-92-249:~$ nvcc --version\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2023 NVIDIA Corporation\n",
    "Built on Tue_Jun_13_19:16:58_PDT_2023\n",
    "Cuda compilation tools, release 12.2, V12.2.91\n",
    "Build cuda_12.2.r12.2/compiler.32965470_0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7795877-6869-4f73-8b4d-200276e90df9",
   "metadata": {},
   "source": [
    "## <a href=torch_install>Torch Installation<a/>\n",
    "\n",
    "PyTorch cuda version should be within a minor version of the cuda drivers and cuda drivers need to align with nvidia drivers.  Try hard to make this happen by paying attention to versions.  \n",
    "\n",
    "```.bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed9f27e-d2b1-4613-8d06-c06b088ecca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available? True.\n",
      "Torch Cuda Version is 12.1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(f\"Is Cuda available? {torch.cuda.is_available()}.\")  # Should return True\n",
    "print(f\"Torch Cuda Version is {torch.version.cuda}.\")  # Should return '12.1'\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4729f-6f5c-4154-9465-ddc6c117b774",
   "metadata": {},
   "source": [
    "### Torch Examples\n",
    "\n",
    "Here are some examples showing that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc3da4c-9a5b-433e-a7f4-c8a2c6fdfb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication on CPU took: 2.8040 seconds\n",
      "Result tensor size on CPU: torch.Size([10000, 10000])\n",
      "Matrix multiplication on GPU took: 0.2448 seconds\n",
      "Result tensor size on GPU: torch.Size([10000, 10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Define the size of the tensors\n",
    "size = 10000\n",
    "\n",
    "# Create two large random tensors for CPU\n",
    "tensor1_cpu = torch.randn(size, size)\n",
    "tensor2_cpu = torch.randn(size, size)\n",
    "\n",
    "# Perform matrix multiplication on the CPU and time it\n",
    "start_time = time.time()\n",
    "result_cpu = torch.matmul(tensor1_cpu, tensor2_cpu)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Matrix multiplication on CPU took: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"Result tensor size on CPU: {result_cpu.size()}\")\n",
    "\n",
    "# Check if CUDA is available and perform the same test on the GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # Create two large random tensors for GPU\n",
    "    tensor1_gpu = tensor1_cpu.to(device)\n",
    "    tensor2_gpu = tensor2_cpu.to(device)\n",
    "\n",
    "    # Perform matrix multiplication on the GPU and time it\n",
    "    torch.cuda.synchronize()  # Ensure all CUDA operations are finished\n",
    "    start_time = time.time()\n",
    "    result_gpu = torch.matmul(tensor1_gpu, tensor2_gpu)\n",
    "    torch.cuda.synchronize()  # Ensure the GPU has finished the computation\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Matrix multiplication on GPU took: {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Result tensor size on GPU: {result_gpu.size()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198ff3a5-283a-4f2e-b8db-6e94b79df549",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stable Baselines 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fdeb1-9a02-454c-ac38-1f13c102a7be",
   "metadata": {},
   "source": [
    "## Install Stable Baselines 3\n",
    "\n",
    "```\n",
    "pip install stable-baselines3[extra]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6ed398-a51b-42b5-a509-a1fd94599c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "import stable_baselines3\n",
    "print(stable_baselines3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2812c9-78a9-44a2-b997-431bc8498d51",
   "metadata": {},
   "source": [
    "## SB3 Example\n",
    "\n",
    "Note, it takes many iteraitons and the proper algorithm to get good results; this just shows it working.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066b6955-d608-4996-9f99-cba81995e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.8     |\n",
      "|    ep_rew_mean     | 22.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 614      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.5        |\n",
      "|    ep_rew_mean          | 27.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007973788 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | 0.00255     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.82        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 38.2       |\n",
      "|    ep_rew_mean          | 38.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 589        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00817219 |\n",
      "|    clip_fraction        | 0.0574     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.669     |\n",
      "|    explained_variance   | 0.146      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.1       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0176    |\n",
      "|    value_loss           | 43.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.1        |\n",
      "|    ep_rew_mean          | 49.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010437099 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.5        |\n",
      "|    ep_rew_mean          | 65.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009758642 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "# Create the CartPole-v1 environment with the \"rgb_array\" render mode\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Create the PPO model (you can replace PPO with other algorithms if you want)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the agent for 10,000 steps\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Test the trained agent and render in the notebook\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Set up the plot for dynamic updates\n",
    "#plt.ion()  # Turn on interactive mode for matplotlib\n",
    "#fig, ax = plt.subplots()\n",
    "\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "\n",
    "    if done or truncated:\n",
    "        obs, info = env.reset()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899a604-34d0-4299-be1c-96aaa804e34c",
   "metadata": {},
   "source": [
    "## Install Transformers and Tokenizers\n",
    "\n",
    "```\n",
    "pip install -U transformers tokenizers\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8825337-4ecb-483b-aff1-f649ee0d4f07",
   "metadata": {},
   "source": [
    "### Transformer and Tokenizer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b96fc0-bb19-4440-88f6-23db75f85940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Transformers are amazing for NLP tasks.\n",
      "Tokenized Input IDs: tensor([[  101, 19081,  2024,  6429,  2005, 17953,  2361,  8518,  1012,   102]])\n",
      "Decoded Text: transformers are amazing for nlp tasks.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sample text\n",
    "text = \"Transformers are amazing for NLP tasks.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get the tokenized input IDs\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# Decode the token IDs back to text\n",
    "decoded_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print original text, tokenized input, and decoded text\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Tokenized Input IDs:\", input_ids)\n",
    "print(\"Decoded Text:\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af7930-6087-4db5-82f9-ae56de146383",
   "metadata": {},
   "source": [
    "### Sentence Transformers\n",
    "\n",
    "```/bash\n",
    "pip install sentence-transformers\n",
    "\n",
    "```\n",
    "\n",
    "Need this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f76f3b-253d-4df7-af11-cac9ee1bd986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asheller/sb3/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/asheller/sb3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.13389921e-02 -2.08391752e-02  3.78195643e-02 -1.00276303e-02\n",
      "  -2.18986664e-02  6.64148200e-03 -4.42283116e-02  4.97135893e-02\n",
      "   2.80648023e-02  1.45602422e-02  2.62472089e-02  8.02669078e-02\n",
      "   4.97584185e-03  8.78880322e-02  4.61270250e-02  3.79769392e-02\n",
      "   3.22095528e-02  1.52603416e-02 -4.78855930e-02 -8.71268734e-02\n",
      "   1.09329306e-01  8.22059810e-02  1.47923604e-02 -5.11702746e-02\n",
      "   5.15239798e-02  6.55859485e-02 -5.36913313e-02 -4.96964194e-02\n",
      "   3.65458801e-02 -9.47064348e-03 -4.13955748e-02  5.72568886e-02\n",
      "  -6.83491975e-02  5.84685169e-02 -6.26850203e-02  7.58528113e-02\n",
      "   1.44350417e-02  1.83785856e-02  1.41708143e-02 -5.39689213e-02\n",
      "  -3.47521044e-02 -1.90681927e-02  1.80511642e-02 -2.25276724e-02\n",
      "   4.55970727e-02 -3.47323082e-02 -2.73609255e-02 -1.98490676e-02\n",
      "  -8.14858940e-04 -2.79270653e-02 -3.95562313e-02 -5.84855042e-02\n",
      "   5.34983799e-02  1.18243903e-01 -1.34977922e-02  2.81568766e-02\n",
      "   8.00181460e-03 -5.52489385e-02  1.07748061e-02 -8.26784372e-02\n",
      "  -7.50691518e-02 -7.26923230e-04 -1.14284502e-02 -3.15912403e-02\n",
      "  -2.56440137e-02 -8.93282518e-03  2.13976521e-02 -1.95715716e-03\n",
      "  -3.98999304e-02  1.71870161e-02 -9.86917391e-02  4.32079621e-02\n",
      "   2.14145575e-02  7.41939843e-02  8.17540959e-02  1.30180074e-02\n",
      "   3.96499559e-02 -1.12352595e-01  1.61439795e-02 -4.75933068e-02\n",
      "   7.10801557e-02 -2.49395519e-02 -1.67709682e-02  1.02371007e-01\n",
      "   6.00531884e-02 -3.79599966e-02 -8.91862670e-04 -1.67397838e-02\n",
      "  -8.11639279e-02 -2.96588126e-03 -8.68672058e-02 -9.48273093e-02\n",
      "   8.75561535e-02  7.51261786e-03 -4.40817177e-02  2.50664782e-02\n",
      "  -4.81076092e-02 -7.26852715e-02  4.49801423e-03  3.30109745e-02\n",
      "  -9.52915382e-03 -2.88514402e-02  2.91740857e-02 -9.59849060e-02\n",
      "  -1.13295607e-01 -7.04405680e-02 -1.06133819e-02  1.11098103e-02\n",
      "  -3.91735928e-03 -4.05783430e-02  3.17186676e-02 -2.89384387e-02\n",
      "  -1.91743057e-02 -4.31948192e-02  6.17150255e-02 -8.93388987e-02\n",
      "   8.42684694e-03 -1.18960775e-02 -2.79276427e-02  3.27752121e-02\n",
      "   1.35773821e-02  7.54369497e-02 -4.16411683e-02  7.63626546e-02\n",
      "   2.60962024e-02 -3.30173410e-02  9.69682485e-02 -2.01159832e-33\n",
      "   8.41613393e-03  9.49250236e-02  4.12810817e-02  3.72696519e-02\n",
      "  -9.30488110e-03  3.43327993e-03 -2.14503445e-02  5.93383312e-02\n",
      "  -3.82257812e-02 -3.54575110e-03 -5.11288568e-02  8.00575092e-02\n",
      "  -1.72844734e-02 -1.36367173e-03 -1.50901889e-02 -6.47914186e-02\n",
      "  -3.30008827e-02  4.24928032e-02 -3.90296616e-02  3.09745930e-02\n",
      "  -6.61236886e-03  4.67417464e-02  3.62695642e-02 -2.47308426e-02\n",
      "  -3.20473835e-02 -3.44663835e-03 -1.98130775e-03 -6.16287068e-02\n",
      "   4.73357961e-02 -1.84988305e-02 -3.48375589e-02  5.97697906e-02\n",
      "  -5.21448776e-02  2.64986027e-02  5.34055196e-03  2.45023635e-03\n",
      "  -2.50871647e-02 -9.50678214e-02 -1.16135553e-02 -1.79991778e-02\n",
      "  -2.73288134e-02  5.74762523e-02 -1.10659637e-01  7.15814019e-03\n",
      "   7.70750120e-02  7.02132359e-02  2.04945216e-03 -4.28030752e-02\n",
      "   2.79471930e-02  1.98839558e-03  3.78897116e-02  5.34533709e-02\n",
      "  -5.07847555e-02  1.97707908e-03  1.83810994e-01 -7.26304250e-03\n",
      "   3.04948557e-02 -4.95861936e-03  1.00949392e-01  2.92118099e-02\n",
      "  -1.23772630e-02  3.00229266e-02  1.59176514e-02 -3.04648522e-02\n",
      "   4.33325544e-02 -2.02232823e-02  5.77010103e-02 -3.25588835e-03\n",
      "  -3.42566491e-04 -1.16551248e-02 -2.14824826e-02 -3.31576131e-02\n",
      "  -8.43156653e-04 -3.40885930e-02  1.86595619e-02  1.45057570e-02\n",
      "   2.44679139e-03 -4.46445160e-02  4.31090742e-02  5.86922094e-02\n",
      "  -4.85014655e-02 -1.19012080e-01  2.97994036e-02 -4.78464402e-02\n",
      "   2.59547234e-02 -4.82602678e-02 -3.18483636e-02 -9.71545726e-02\n",
      "   4.57095075e-03 -9.06092208e-03 -8.83207773e-04  2.50314083e-02\n",
      "  -2.26742476e-02  4.16882150e-03  5.73514123e-03  9.56815300e-34\n",
      "  -3.73278372e-02 -1.25536090e-02 -1.03082284e-01  9.87607911e-02\n",
      "  -2.94563267e-02 -1.43612670e-02 -3.82837094e-02  2.79907938e-02\n",
      "   2.47576665e-02  5.60509153e-02 -8.17170367e-03 -3.16256359e-02\n",
      "  -3.93590778e-02 -2.18429267e-02  1.09793998e-01 -6.70883358e-02\n",
      "   4.63267975e-02 -1.40530188e-02  4.11658958e-02  8.68671983e-02\n",
      "   1.58836339e-02  1.58808187e-01 -1.29776895e-01  4.66321073e-02\n",
      "  -9.48791765e-03  6.40924573e-02 -1.15770921e-01  7.14270584e-03\n",
      "   1.17837684e-02  9.03238356e-03 -4.31012623e-02 -1.03710387e-02\n",
      "  -1.86151713e-02 -2.15607733e-02 -5.08089177e-02 -1.17473891e-02\n",
      "  -2.72203423e-02 -1.23246983e-02 -2.62995921e-02  1.65909808e-02\n",
      "   3.03094760e-02  3.99106108e-02 -2.81110965e-02  2.47760918e-02\n",
      "  -9.52601433e-02 -6.82688504e-02 -3.33690718e-02 -4.25384268e-02\n",
      "  -2.54374859e-03  7.71383941e-02 -3.54083627e-02  1.09947119e-02\n",
      "  -1.12818219e-01 -1.21028408e-01 -1.52590489e-02 -5.44914491e-02\n",
      "   5.40056191e-02 -1.03101231e-01  2.88094133e-02 -1.97712146e-02\n",
      "  -9.30150822e-02  2.82325260e-02  8.50701779e-02 -5.99852428e-02\n",
      "   2.28142012e-02 -3.07087321e-02  1.59088001e-02 -2.78398748e-02\n",
      "  -2.87901727e-03 -2.72179078e-02  6.62282556e-02  3.70688252e-02\n",
      "   2.64303014e-02 -3.94684635e-02 -1.07483603e-02 -1.19047947e-02\n",
      "   4.18200493e-02  7.88503978e-03 -2.53780652e-02 -6.98991641e-02\n",
      "   3.05062160e-02  8.73475056e-03  5.21765053e-02  2.98741274e-02\n",
      "   1.51348906e-02  8.98343474e-02 -1.84008684e-02  1.12342322e-03\n",
      "   3.24808657e-02  6.21275641e-02 -3.42305936e-02  3.46833728e-02\n",
      "   2.67563183e-02  1.13286532e-01  1.31214308e-02 -1.58217208e-08\n",
      "  -5.14110997e-02  5.96944056e-02 -3.73664685e-02 -1.06354645e-02\n",
      "  -1.42139578e-02 -4.84035872e-02  3.31888273e-02  8.29870030e-02\n",
      "  -3.32707241e-02 -3.35256831e-04  9.80553329e-02 -4.55461815e-02\n",
      "   9.90803540e-03  4.91861030e-02  1.17603973e-01  1.87714342e-02\n",
      "   7.86552504e-02 -6.34163944e-03 -3.67030315e-02  8.07171408e-03\n",
      "  -8.98551429e-04  8.72058272e-02 -5.00192679e-02  8.99784360e-03\n",
      "  -2.44703200e-02  2.10707188e-02 -3.14435773e-02 -4.93638404e-02\n",
      "   2.44295374e-02 -1.39967753e-02  3.58098862e-03  4.92439009e-02\n",
      "  -2.20063254e-02  4.35395539e-02  5.47413826e-02  2.43605152e-02\n",
      "   7.40203410e-02 -7.40141198e-02 -1.90981664e-02 -3.42055336e-02\n",
      "   7.88777173e-02  7.65522420e-02 -9.69668478e-02  3.22016701e-02\n",
      "   4.90539372e-02 -2.78660166e-03  4.22286578e-02 -1.70268342e-01\n",
      "  -3.40080559e-02  3.91160324e-03  7.40143191e-03 -2.76136864e-02\n",
      "  -4.57473993e-02  2.54089646e-02  7.90525377e-02  3.73700671e-02\n",
      "   4.22542617e-02 -7.54245967e-02 -5.92881404e-02  7.13606626e-02\n",
      "   1.18065095e-02  7.82025307e-02  1.94492266e-02  4.77532372e-02]\n",
      " [-3.65064223e-03 -4.02566567e-02  5.37926182e-02  1.87592860e-02\n",
      "   4.36548814e-02  1.07265830e-01  1.37052024e-02  5.64765744e-02\n",
      "   3.83178592e-02 -3.81296352e-02  4.78521362e-02  4.42149639e-02\n",
      "   2.23990604e-02  6.06395453e-02  2.15431582e-02  3.58680412e-02\n",
      "   8.68860409e-02  9.80533510e-02 -7.73597434e-02 -8.74792561e-02\n",
      "  -4.10939530e-02  2.51762867e-02  6.71608299e-02 -6.30397201e-02\n",
      "   7.63508491e-03 -9.63678956e-03 -6.72210231e-02  3.96238826e-03\n",
      "   6.95275590e-02  2.14077290e-02 -2.73867813e-03 -4.66553541e-03\n",
      "  -2.08296683e-02  2.78403368e-02 -1.73364449e-02  2.82478388e-02\n",
      "   4.42461185e-02  1.06463179e-01 -4.13178653e-02 -2.04074774e-02\n",
      "   8.36501643e-03  2.78143100e-02  5.13444021e-02  6.12559691e-02\n",
      "   5.86420111e-02 -5.18060178e-02 -6.59484565e-02 -2.18247734e-02\n",
      "  -4.19921428e-02  4.15930487e-02 -6.09701537e-02 -2.82707736e-02\n",
      "  -3.88227999e-02  2.98456065e-02  2.10315231e-02 -6.47074264e-03\n",
      "  -3.32621187e-02 -1.17579205e-02  1.10785626e-02 -9.81175229e-02\n",
      "   1.67630184e-02 -5.59938848e-02 -3.41848806e-02  4.53319028e-02\n",
      "   3.42978798e-02 -6.97385846e-03  3.40199703e-03  5.35050482e-02\n",
      "  -5.67048714e-02  1.18010879e-01 -3.72043401e-02  2.63291076e-02\n",
      "  -8.92801434e-02  3.48124467e-02 -7.75281042e-02  4.94075306e-02\n",
      "   5.68245761e-02 -1.02483310e-01  6.50745481e-02 -2.24783309e-02\n",
      "  -3.21006216e-02 -2.35492233e-02  1.46478647e-02 -1.28406356e-03\n",
      "   1.17351934e-01 -1.12275062e-02  7.39701018e-02 -6.42865747e-02\n",
      "  -6.89552277e-02  2.77736951e-02  8.26347340e-03 -7.05972463e-02\n",
      "   4.64272201e-02 -6.82024425e-03  9.92725790e-03 -1.55898621e-02\n",
      "  -3.29161733e-02 -2.54919678e-02  1.22037698e-02  6.56328499e-02\n",
      "   3.29815447e-02  2.29997467e-02  7.80922174e-02  3.18651204e-03\n",
      "  -4.98883054e-02 -3.59911919e-02 -2.51076669e-02  1.59666054e-02\n",
      "   3.59948096e-03 -7.74266124e-02 -1.08642377e-01  4.89926040e-02\n",
      "  -2.34071538e-02  1.15038715e-02  5.48987538e-02 -2.53492687e-02\n",
      "   1.77408904e-02 -5.13560325e-02  4.09484953e-02 -1.90767087e-02\n",
      "  -2.71398108e-02  5.08160926e-02 -4.04529311e-02  4.74189706e-02\n",
      "   1.87084451e-02 -7.64882714e-02  1.77136511e-02 -3.10000782e-33\n",
      "  -1.21809198e-02  2.59609837e-02 -1.91357732e-02  6.19516708e-02\n",
      "   9.14467592e-03  1.42611684e-02 -4.55985107e-02  6.13453090e-02\n",
      "  -8.51536319e-02 -3.42710055e-02 -3.82091999e-02  5.97606562e-02\n",
      "   1.83344614e-02  1.04790768e-02  5.01671731e-02  1.86543018e-02\n",
      "  -2.31891274e-02  1.37787797e-02  1.65509409e-03  2.48640850e-02\n",
      "  -5.38350418e-02 -1.85126010e-02 -2.82225106e-03 -3.37435454e-02\n",
      "  -3.69313620e-02 -2.38055419e-02  1.20403051e-01 -6.21039867e-02\n",
      "  -4.12109010e-02  2.42502801e-02 -5.59023507e-02 -3.04966774e-02\n",
      "  -6.82481825e-02 -1.79481674e-02  2.20057694e-03  1.10732894e-02\n",
      "   1.02065667e-03 -3.48261222e-02  1.49891879e-02 -8.75049829e-03\n",
      "  -5.40851103e-03 -2.03851257e-02 -9.91616864e-03  2.04789173e-03\n",
      "   1.04808910e-02  1.72010728e-03 -9.23038926e-03 -3.43419090e-02\n",
      "   1.65516641e-02 -4.56563234e-02  1.09757846e-02  2.34714523e-02\n",
      "  -3.89113906e-03 -1.08842574e-01  1.05601974e-01 -2.06440035e-02\n",
      "  -1.60452276e-02  1.41883194e-02  2.73804460e-02 -4.69094031e-02\n",
      "  -1.50368148e-02  1.98541693e-02  9.58696231e-02 -3.54821235e-02\n",
      "  -3.42407823e-02  7.78523758e-02 -5.04241139e-02 -2.30546426e-02\n",
      "   1.91291664e-02  2.52683349e-02 -6.17241636e-02  3.61112356e-02\n",
      "  -2.04768833e-02 -6.49498776e-03 -4.58281040e-02  6.94495365e-02\n",
      "  -5.43259345e-02 -1.00172468e-01  3.08690518e-02  1.17122814e-01\n",
      "  -3.66334408e-03 -1.84244588e-01  1.39172198e-02 -1.40381157e-02\n",
      "  -3.96210179e-02 -1.41388044e-01  5.43646887e-02 -8.71689096e-02\n",
      "   6.75088242e-02  2.89072990e-02 -1.67963710e-02 -9.78565123e-03\n",
      "  -4.55209166e-02 -1.96132227e-03 -2.68604290e-02  1.68949946e-33\n",
      "  -3.31909470e-02  1.94348674e-02 -6.68849126e-02  6.47821128e-02\n",
      "  -8.55551939e-03  2.43361052e-02 -6.32420555e-02  1.61887985e-02\n",
      "  -2.44753119e-02 -1.50398603e-02 -8.92010033e-02  1.34052122e-02\n",
      "   4.28511240e-02 -4.46366183e-02  2.76253633e-02  5.50354226e-03\n",
      "  -4.14503925e-02  2.03786362e-02 -1.62264463e-02  4.22022641e-02\n",
      "   1.41472858e-03  9.94222984e-02 -5.71460053e-02  7.38419816e-02\n",
      "   4.14964668e-02  8.90614763e-02 -6.04642145e-02 -7.20138103e-02\n",
      "  -1.31157205e-01 -5.55767156e-02 -3.43461074e-02 -4.77558486e-02\n",
      "  -3.85388993e-02 -4.77392226e-02 -5.84640130e-02  3.23132165e-02\n",
      "   7.33682886e-02 -4.08574119e-02 -1.83145478e-02 -3.50779593e-02\n",
      "   5.94206378e-02  5.31809032e-02 -1.55666191e-02  2.80934609e-02\n",
      "  -1.04945963e-02 -1.43888351e-02 -7.55968317e-02 -1.17197651e-02\n",
      "   7.57965669e-02  5.81873655e-02 -4.25755717e-02  3.81851383e-02\n",
      "  -8.37945417e-02 -5.61070368e-02 -1.72014683e-02 -5.63367307e-02\n",
      "   2.60048429e-03 -1.02772854e-01 -1.26566074e-03 -1.56447925e-02\n",
      "  -1.09514207e-01 -3.83283640e-03  3.97503600e-02 -4.62057777e-02\n",
      "   5.93802184e-02 -1.39045328e-01 -3.16912457e-02  6.14067838e-02\n",
      "  -2.19795178e-03 -9.27408114e-02  1.07508497e-02 -3.91481491e-03\n",
      "  -3.00360788e-02  5.58332838e-02 -3.05787716e-02 -2.35126130e-02\n",
      "   3.72293256e-02  1.56597029e-02 -6.71998486e-02 -6.47744089e-02\n",
      "   8.87671337e-02 -7.48190582e-02  6.93876520e-02 -3.46382782e-02\n",
      "   3.34317610e-02  7.62093663e-02  3.34793329e-02 -2.96906591e-03\n",
      "   2.07741465e-02 -8.93888157e-03 -6.33103251e-02 -1.24690728e-02\n",
      "  -1.75032131e-02  1.17574804e-01  3.06493230e-02 -1.57106008e-08\n",
      "  -6.15324192e-02 -2.43087728e-02  5.48808724e-02  3.30633111e-02\n",
      "  -7.56444111e-02 -7.11502209e-02 -2.29836665e-02  6.43548295e-02\n",
      "  -5.09497635e-02 -3.36610992e-03  5.79673164e-02  2.19356380e-02\n",
      "  -6.35055006e-02  1.38764251e-02  4.74086031e-02  4.33154330e-02\n",
      "   5.74722653e-03 -1.79616287e-02 -3.80584947e-03  2.26670150e-02\n",
      "   5.74051514e-02  1.11191228e-01 -6.37345808e-03  4.52824831e-02\n",
      "  -1.78188942e-02  3.89134735e-02  1.69905499e-02  3.40933651e-02\n",
      "   2.54978687e-02  2.16917731e-02  5.06390706e-02  8.18910152e-02\n",
      "  -9.80569422e-03  4.50543920e-03  4.65276465e-02  1.29042074e-01\n",
      "   7.15280399e-02 -1.00725017e-01 -2.45614618e-04 -3.17353918e-03\n",
      "   5.04630245e-02  6.68728128e-02 -8.23084339e-02  3.21189687e-02\n",
      "   1.00300260e-01  4.13458096e-03  2.14018710e-02 -4.83180396e-02\n",
      "  -4.03572656e-02  3.44823976e-03  3.83812264e-02 -5.31095900e-02\n",
      "   5.30552864e-03  1.54014677e-02  3.79170217e-02  3.94546129e-02\n",
      "   3.25820893e-02 -2.72934027e-02 -5.38105424e-03  3.48102413e-02\n",
      "  -9.61134303e-03  1.74200445e-01  3.71564329e-02 -4.88809915e-03]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode a list of sentences\n",
    "sentences = [\"Transformers are amazing for NLP tasks.\", \"Sentence embeddings are useful.\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the sentence embeddings\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727ee5a-377c-42ed-95f0-01cc268afd01",
   "metadata": {},
   "source": [
    "## Setup Summary -- \n",
    "\n",
    "More notes can be added here but Pytorch, and Stable Baselines 3 are the two main modules.  Extras required from both will come up but should not be a huge issue.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
